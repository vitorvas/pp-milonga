#pragma omp for ordered(n) collapse(n)

#pragma omp for ordered(n) depend(sink:...)

#pragma omp for ordered(n) depende(source)

Isso e pra usar doacross pattern de forma paralelizada.
Se estudar com carinho, pode ser que seja util no milonga.

-----------------------------------------------------------------

/home/vitor/software/milonga/wasora/src/mesh/neighbors.c:int mesh_count_common_nodes(element_t *e1, element_t *e2, int *nodes)

Essa eh uma funcao candidata. Ainda eh necessario saber
seu perfil com detalhes, mas no seu corpo
trata-se de um loop que compara nos em comum entre
elementos da malha.

Os nos em comum sao armazenados no vetor nodes.
Um reduce resolve facil isso.
Testar.

-----------------------------------------------------------------

3.2.3 Iteration (Book).

O conceito de loop-carried-dependencies eh um conceito importante na
paralelizacao de loos de iteracao. A funcao escolhida nao apresenta esse
tipo de dependencia. Ao explicar isso no paper, fazer essa referencia.

-----------------------------------------------------------------

Iniciar o processo de profiling considerando consumo de memória e tempo.
Para isso, cada execução de profiling vai ser precedida da execução 
com -O3 (ou -O2) do milonga. Com isso vou poder medir direito o desempenho.

Ver como automatizar isso e conferir, ao mesmo tempo, consumo de memória 
e tempo. E fazer inicialmente apenas para FEM enquanto o FVM não estiver 
100% com o exemplo utilizado. Pretendo usar só um inicialmente.


-----------------------------------------------------------------
Assim para debugar o milonga usando o mpirun. Notar que para cada processo ele vai abrir
um xterm diferente e cada debug será feito em um processo.

mpirun -np 2 xterm -e gdb --args /home/vitors/workspace/development/milonga-vitor/milonga profiling.mil --volumes --diffusion tet-s volumes diffusion


-----------------------------------------------------------------
O erro abaixo ocorre quando a biblioteca petsc está compilada como debug.
Como release, são executadas duas funções do milonga idênticas separadamente.
A ideia é entender onde usa acontece e como o milonga usa as funções petsc para
construir as matrizes.

(gdb) backtrace
#0  VecGetValues_MPI (xin=0x163c6d0, ni=1, ix=0x152acb0, y=0x166af30) at /home/vitors/libs/petsc-3.9.2/src/vec/vec/impls/mpi/pdvec.c:921
#1  0x00007ffff5cc9a25 in VecGetValues (x=0x163c6d0, ni=1, ix=0x152acb0, y=0x166af30) at /home/vitors/libs/petsc-3.9.2/src/vec/vec/interface/rvector.c:899
#2  0x000000000041d2b9 in diffusion_volumes_results_fill_flux () at ./discretizations/diffusion_volumes.c:453
#3  0x0000000000411295 in milonga_instruction_step (arg=0x870290) at ./milonga.c:118
#4  0x0000000000442ce9 in wasora_step (whence=0) at ../wasora/src/wasora.c:399
#5  0x00000000004423db in wasora_standard_run () at ../wasora/src/wasora.c:199
#6  0x00000000004422d2 in main (argc=5, argv=0x7fffffffc3a8) at ../wasora/src/wasora.c:159
